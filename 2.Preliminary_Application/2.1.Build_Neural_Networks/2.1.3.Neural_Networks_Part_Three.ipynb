{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## backpropagation 反向传播",
   "id": "31c53eef690e47f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    在Pytorch中执行反向传播非常简便，全部的操作就是loss.backward()\n",
    "    在执行反向传播之前，要先将梯度清零，否则梯度会在不同的批次数据之间被累加"
   ],
   "id": "b8dbcc95e1b69a9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:11:01.983779Z",
     "start_time": "2024-07-23T16:11:01.974798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from Neural_Networks import Net\n",
    "\n",
    "input = torch.randn(1, 1, 32, 32)\n",
    "net = Net()\n",
    "output = net(input)\n",
    "print(\"input:\\n\", input)\n",
    "print(\"output:\\n\", output)\n",
    "\n",
    "# 损失函数\n",
    "target = torch.randn(10)\n",
    "target = target.view(1, -1)\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output, target)\n",
    "print(\"loss:\\n\", loss)\n",
    "\n",
    "# 反向传播\n",
    "# Pytorch中执行梯度清零的代码\n",
    "net.zero_grad()\n",
    "\n",
    "print(\"conv1.bias.grad before backward\")\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "# Pytorch中执行反向传播的代码\n",
    "loss.backward()\n",
    "\n",
    "print(\"conv1.bias.grad after backward\")\n",
    "print(net.conv1.bias.grad)"
   ],
   "id": "c42c98a6a9409641",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " tensor([[[[ 0.9366, -0.5252, -1.6529,  ..., -0.9564, -0.6649,  1.5528],\n",
      "          [ 1.1307,  2.1657,  0.4001,  ..., -0.8488, -0.0939,  1.0208],\n",
      "          [-0.6735,  1.5474, -1.7888,  ...,  0.1283,  0.5225, -0.8565],\n",
      "          ...,\n",
      "          [-1.3185,  1.0852,  0.6869,  ...,  2.1979,  1.6541, -1.8709],\n",
      "          [ 0.7383,  0.1899,  0.7138,  ..., -0.7484,  2.3936,  0.8467],\n",
      "          [-1.7614,  0.4754,  0.4819,  ..., -0.0679, -0.9611, -0.4534]]]])\n",
      "output:\n",
      " tensor([[ 0.1021,  0.1454,  0.0733, -0.0405,  0.0026, -0.0070,  0.1473, -0.0045,\n",
      "          0.0162, -0.1000]], grad_fn=<AddmmBackward0>)\n",
      "loss:\n",
      " tensor(0.8045, grad_fn=<MseLossBackward0>)\n",
      "conv1.bias.grad before backward\n",
      "None\n",
      "conv1.bias.grad after backward\n",
      "tensor([ 0.0058,  0.0026,  0.0124, -0.0028, -0.0182, -0.0034])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f2b7d44d5144e585"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
